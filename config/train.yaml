hydra:
  run:
    dir: /media/dmitry/data/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model/effdet/base
  - model: effdet/tf_d3

general:
  gpu: 1
  seed: 333

distributed:
  backend: nccl
  url: env://

data:
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  train:
    class: data.dataset.ExtendedWheatDataset
    params:
      image_dir: /media/dmitry/data/global-wheat-detection/train
      csv: /media/dmitry/data/global-wheat-detection/train.csv
      gen_image_dirs:
        - /media/dmitry/data/global-wheat-detection/synthetic/2020-07-19/15-13-08
      source: [ethz_1, arvalis_1, rres_1, arvalis_3]
      show_progress: false
    orig_images_ratio: 0.5
    loader:
      # batch size per each device
      batch_size: 2
      workers: 2
    transforms:
      resize:
        class: albumentations.Resize
        params:
          height: 896
          width: 896
          interpolation: 3  # cv2.INTER_AREA
      flip:
        class: albumentations.Flip
        params:
          p: 0.75
      rotate90:
        class: albumentations.RandomRotate90
        params:
          p: 0.75
      affine:
        class: data.transforms.affine
        params:
          shift_limit: 0
          scale_limit: [0.05, 0.15]
          rotate_limit: 25
          p: 0.33
      color:
        class: data.transforms.color_jitter
        params:
          brightness_limit: 0.2
          contrast_limit: 0.2
          brightness_by_max: true
          r_shift_limit: 20
          g_shift_limit: 20
          b_shift_limit: 20
          hue_shift_limit: 15
          sat_shift_limit: 30
          val_shift_limit: 10
          p: 0.75
      enhance:
        class: data.transforms.enhancer
        params:
          blur_limit: 5
          p: 0.33
  val:
    class: data.dataset.WheatDataset
    params:
      image_dir: /media/dmitry/data/global-wheat-detection/train
      csv: /media/dmitry/data/global-wheat-detection/train.csv
      source: [usask_1, arvalis_2, inrae_1]
      show_progress: false
    loader:
      batch_size: 4
      workers: 2
    transforms:
      resize:
        class: albumentations.Resize
        params:
          height: 896
          width: 896
          interpolation: 3  # cv2.INTER_AREA

model:
  class: effdet.create_model_from_config
  params:
    config:
      pretrained_backbone: true
      num_classes: 1
    bench_name: train
    pretrained: false
    checkpoint_path: ''

# loss inside DetTrainBench
# TODO: maybe add option for alternative losses

optim:
  class: torch.optim.SGD
  params:
    lr: 0.01  # max_lr = 0.016, batch_size = 128
    momentum: 0.9
    weight_decay: 4e-5
    nesterov: false
  step_interval: 5

lr_scheduler:
  # https://github.com/rwightman/pytorch-image-models/blob/master/timm/scheduler/cosine_lr.py
  # https://github.com/rwightman/efficientdet-pytorch/blob/master/train.py
  class: timm.scheduler.cosine_lr.CosineLRScheduler
  params:
    # num epochs
    t_initial: 100
    # learning rate cycle len multiplier
    t_mul: 1.0
    # lower lr bound for cyclic schedulers that hit 0
    lr_min: 1e-5
    # LR decay rate
    decay_rate: 0.1
    warmup_lr_init: 0.0001
    # epochs to warmup LR
    warmup_t: 5
    # learning rate cycle limit
    cycle_limit: 1
    t_in_epochs: true
    noise_range_t: ~
    noise_pct: 0.67
    noise_std: 1.0
    noise_seed: 333

# EMA of the model weights, alpha - decay rate
smoothing:
  enabled: true
  use_cpu: true
  alpha: 0.998
  interval_it: 1

train:
  skip: false
  epochs: 100
  epoch_length: -1

validate:
  interval_ep: 1
  calc_map: true

# Renders target and predicted bboxes on top of each image in the validation dataset.
visualize:
  enabled: true
  save_dir: ~
  num_images: 32
  interval_ep: 10

checkpoints:
  load: ~
  save_dir: ~
  interval_ep: 1
  interval_it: 500
  max_checkpoints: 100

logging:
  model: false
  interval_it: 100
  out:
    train:
      - loss
      - box_loss
    val:
      - loss
      - box_loss
