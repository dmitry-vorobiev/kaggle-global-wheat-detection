hydra:
  run:
    dir: /media/dmitry/data/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model/effdet/base
  - model: effdet/tf_d3
  - optim: adamw
  - scheduler: one_cycle
#  - optim: sgd
#  - scheduler: cosine

gpu: 1
seed: 333
# use Nvidia's Apex package
use_apex: true

# params, which will be passed to amp.initialize(...)
amp:
  opt_level: O1
  num_losses: 1
  verbosity: 0

distributed:
  backend: nccl
  url: env://
  sync_bn: false
  dist_bn: reduce

data:
  mean: [0.485, 0.456, 0.406]
  std: [0.229, 0.224, 0.225]
  train:
    class: data.dataset.ExtendedWheatDataset
    params:
      image_dir: /media/dmitry/data/global-wheat-detection/train
      csv: /media/dmitry/data/global-wheat-detection/train.csv
      gen_image_dirs:
        - /media/dmitry/data/global-wheat-detection/synthetic/0_20_x2/2020-07-30/11-52-23
        - /media/dmitry/data/global-wheat-detection/synthetic/0_225_x2/2020-07-31/12-12-11
        - /media/dmitry/data/global-wheat-detection/synthetic/0_25_x2/2020-07-30/12-55-50
        - /media/dmitry/data/global-wheat-detection/synthetic/0_275_x2/2020-07-30/20-45-00
        - /media/dmitry/data/global-wheat-detection/synthetic/0_30_x2/2020-07-30/15-01-01
        - /media/dmitry/data/global-wheat-detection/synthetic/0_325_x2/2020-07-31/10-54-53
      source: ~
      show_progress: false
      p_mosaic: 0.45
      mosaic_num_orig: 2
      box_format: yxyx
    bbox_params:
      format: pascal_voc
      min_visibility: 0.1
    orig_images_ratio: 0.5
    loader:
      # batch size per each device
      batch_size: 4
      workers: 1
      prefetch: true
    transforms:
      resize:
        class: data.transforms.resize_or_crop
        params:
          height: 896
          width: 896
          # INTER_NEAREST, INTER_LINEAR, INTER_CUBIC, INTER_AREA
          interpolation: [0, 1, 2, 3]
      flip:
        class: albumentations.Flip
        params:
          p: 0.75
      rotate90:
        class: albumentations.RandomRotate90
        params:
          p: 0.75
      color:
        class: data.transforms.color_jitter
        params:
          brightness_limit: 0.2
          contrast_limit: 0.2
          brightness_by_max: true
          r_shift_limit: 30
          g_shift_limit: 30
          b_shift_limit: 30
          hue_shift_limit: 20
          sat_shift_limit: 50
          val_shift_limit: 30
          p: 0.75
      enhance:
        class: data.transforms.enhancer
        params:
          noise_var_limit: [25.0, 60.0]
          p: 0.25
    affine_tfm:
      affine:
        class: data.transforms.affine
        params:
          shift_limit: 0
          scale_limit: [-0.05, 0.45]
          rotate_limit: 15
          interpolation: 2  # INTER_CUBIC
          border_mode: 0
          p: 0.33
    affine_tfm_mosaic:
      affine:
        class: data.transforms.affine
        params:
          shift_limit: 0.03
          scale_limit: [-0.3, 0.15]
          rotate_limit: 20
          interpolation: 2  # INTER_CUBIC
          border_mode: 0
          p: 0.9
      crop:
        class: albumentations.CenterCrop
        params:
          height: 896
          width: 896
  val:
    class: data.dataset.WheatDataset
    params:
      image_dir: /media/dmitry/data/global-wheat-detection/train
      csv: /media/dmitry/data/global-wheat-detection/train.csv
      source: [usask_1, arvalis_2, inrae_1]
      show_progress: false
      box_format: yxyx
    bbox_params:
      format: pascal_voc
      min_visibility: 0.05
    loader:
      batch_size: 10
      workers: 2
      prefetch: true
    transforms:
      resize:
        class: albumentations.Resize
        params:
          height: 896
          width: 896
          interpolation: 2  # INTER_CUBIC

model:
  class: models.efficient_det.create_model_from_config
  params:
    config:
      num_classes: 90  # to load pretrained weights
      pretrained_backbone: false
      box_loss: ciou
      box_loss_weight: 10.0
    bench_name: train
    pretrained: true
    checkpoint_path: ''

optim:
  clip_grad: 10.0
  step_interval: 4 # bs = 4 * 2 gpus; eff_bs = 32

# EMA of the model weights, alpha - decay rate
smoothing:
  enabled: true
  use_cpu: true
  alpha: 0.998
  interval_it: 1

train:
  skip: false
  epochs: 100
  epoch_length: -1

validate:
  interval_ep: 100
  calc_map: true
  min_score: 0.1

# Renders target and predicted bboxes on top of each image in the validation dataset.
visualize:
  enabled: true
  save_dir: ~
  num_images: 32
  min_score: 0.1
  interval_ep: 10

checkpoints:
  load: ~
  save_dir: ~
  interval_ep: 1
  interval_it: 500
  max_checkpoints: 100

logging:
  model: false
  interval_it: 100
  out:
    train:
      - loss
      - box_loss
    val:
      - loss
      - box_loss
      - class_loss
