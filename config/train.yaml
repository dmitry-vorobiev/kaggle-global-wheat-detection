hydra:
  run:
    dir: /media/dmitry/data/outputs/${now:%Y-%m-%d}/${now:%H-%M-%S}

defaults:
  - model/effdet/base
  - model: effdet/d1

general:
  gpu: 1
  seed: 333

distributed:
  backend: nccl
  url: env://

data:
  train:
    # params is passed to the dataset class __init__
    params:
      image_dir: /media/dmitry/data/global-wheat-detection/train
      csv: /media/dmitry/data/global-wheat-detection/train.csv
      # split data by source
      source: [ethz_1, arvalis_1, rres_1, arvalis_3]
    loader:
      # batch size per each device
      batch_size: 8
      workers: 2
    transforms:
      flip:
        class: albumentations.Flip
      rotate90:
        class: albumentations.RandomRotate90
      resize:
        class: albumentations.Resize
        params:
          height: 640
          width: 640
          interpolation: 3  # cv2.INTER_AREA
      normalize:
        class: albumentations.Normalize
        params:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
      to_torch:
        class: albumentations.pytorch.transforms.ToTensorV2
  val:
    params:
      image_dir: /media/dmitry/data/global-wheat-detection/train
      csv: /media/dmitry/data/global-wheat-detection/train.csv
      source: [usask_1, arvalis_2, inrae_1]
    loader:
      batch_size: 16
      workers: 2
    transforms:
      resize:
        class: albumentations.Resize
        params:
          height: 640
          width: 640
          interpolation: 3  # cv2.INTER_AREA
      normalize:
        class: albumentations.Normalize
        params:
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]
      to_torch:
        class: albumentations.pytorch.transforms.ToTensorV2

model:
  class: effdet.create_model_from_config
  params:
    config:
      pretrained_backbone: true
      num_classes: 1
    bench_name: train
    pretrained: false
    checkpoint_path: ''

# loss inside DetTrainBench
# TODO: maybe add option for alternative losses

optim:
  class: torch.optim.Adam
  params:
    lr: 0.001
    betas: [0.9, 0.999]
    eps: 1e-8
  step_interval: 1

train:
  skip: false
  epochs: 100
  epoch_length: -1

validate:
  interval_ep: 1

# Renders target and predicted bboxes on top of each image in the validation dataset.
visualize:
  enabled: true
  save_dir: ~
  num_images: 32
  interval_ep: 10

checkpoints:
  load: ~
  save_dir: ~
  interval_ep: 1
  interval_it: 500
  max_checkpoints: 100

logging:
  model: false
  interval_it: 100
  out:
    - loss
    - class_loss
    - box_loss
